{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V5E1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "WAx2CjtHcRvd",
        "outputId": "3519a4f2-d13a-4ff9-b25c-5a797da91d09"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid character '‚úÖ' (U+2705) (ipython-input-2021825122.py, line 139)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-2021825122.py\"\u001b[0;36m, line \u001b[0;32m139\u001b[0m\n\u001b[0;31m    ‚úÖ ƒêang ch·∫°y tr√™n thi·∫øt b·ªã: cpu\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character '‚úÖ' (U+2705)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "Open In Colab\n",
        "\n",
        "# --- PH·∫¶N 1: IMPORT TH∆Ø VI·ªÜN ---\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "import math\n",
        "\n",
        "# Ch·ªçn thi·∫øt b·ªã\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"‚úÖ ƒêang ch·∫°y tr√™n thi·∫øt b·ªã: {device}\")\n",
        "\n",
        "\n",
        "# --- PH·∫¶N 2: KHAI B√ÅO KI·∫æN TR√öC MODEL (B·∫ÆT BU·ªòC) ---\n",
        "# M√°y t√≠nh c·∫ßn bi·∫øt khung x∆∞∆°ng c·ªßa CNN tr∆∞·ªõc khi n·∫°p tr·ªçng s·ªë\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        # Layer 1: Nh√¨n chi ti·∫øt\n",
        "        self.conv1 = nn.Conv2d(1, 24, kernel_size=3)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        # Layer 2: Nh√¨n t·ªïng qu√°t\n",
        "        self.conv2 = nn.Conv2d(24, 36, kernel_size=3)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(36 * 5 * 5, 128)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(128, 10) # Output 10 s·ªë (0-9)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool2(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# --- PH·∫¶N 3: LOAD MODEL T·ª™ FILE .PTH ---\n",
        "print(\"\\n‚è≥ ƒêang load model...\")\n",
        "cnn_model = CNN().to(device) # T·∫°o x√°c model\n",
        "\n",
        "try:\n",
        "    # N·∫°p \"tr√≠ tu·ªá\" (weights) v√†o x√°c model\n",
        "    cnn_model.load_state_dict(torch.load('mnist_cnn_model1.pth', map_location=device))\n",
        "    cnn_model.eval() # Chuy·ªÉn sang ch·∫ø ƒë·ªô thi ƒë·∫•u (Demo)\n",
        "    print(\"‚úÖ Load model th√†nh c√¥ng! S·∫µn s√†ng demo.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"‚ùå L·ªñI: Kh√¥ng t√¨m th·∫•y file 'mnist_cnn_model.pth'.\")\n",
        "    print(\"üëâ H√£y k√©o th·∫£ file .pth v√†o m·ª•c Files b√™n tr√°i m√†n h√¨nh r·ªìi ch·∫°y l·∫°i.\")\n",
        "\n",
        "\n",
        "# --- PH·∫¶N 4: H√ÄM X·ª¨ L√ù ·∫¢NH \"X·ªäN\" (PRE-PROCESSING) ---\n",
        "def preprocess_digit(image_path):\n",
        "    # ƒê·ªçc ·∫£nh x√°m\n",
        "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "    if img is None: return None\n",
        "\n",
        "    # T√°ch n·ªÅn v√† ch·ªØ (Otsu Threshold)\n",
        "    # THRESH_BINARY_INV: Gi·∫£ ƒë·ªãnh ·∫£nh g·ªëc l√† n·ªÅn tr·∫Øng ch·ªØ ƒëen -> ƒê·∫£o th√†nh n·ªÅn ƒëen ch·ªØ tr·∫Øng\n",
        "    _, img_binary = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)\n",
        "\n",
        "    # L·ªçc nhi·ªÖu\n",
        "    kernel = np.ones((3,3), np.uint8)\n",
        "    img_binary = cv2.morphologyEx(img_binary, cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "    # T√¨m ƒë∆∞·ªùng bao c·ªßa ch·ªØ s·ªë\n",
        "    contours, _ = cv2.findContours(img_binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    if not contours: return np.zeros((28, 28), dtype=np.float32)\n",
        "\n",
        "    # L·∫•y ƒë∆∞·ªùng bao l·ªõn nh·∫•t (l√† ch·ªØ s·ªë)\n",
        "    c = max(contours, key=cv2.contourArea)\n",
        "    x, y, w, h = cv2.boundingRect(c)\n",
        "    digit_roi = img_binary[y:y+h, x:x+w]\n",
        "\n",
        "    # Resize v·ªÅ 20x20 (gi·ªØ t·ª∑ l·ªá)\n",
        "    max_dim = max(w, h)\n",
        "    scale_factor = 20.0 / max_dim\n",
        "    new_w = int(w * scale_factor)\n",
        "    new_h = int(h * scale_factor)\n",
        "    digit_resized = cv2.resize(digit_roi, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "    # ƒê·∫∑t v√†o gi·ªØa khung 28x28\n",
        "    final_img = np.zeros((28, 28), dtype=np.uint8)\n",
        "    start_x = (28 - new_w) // 2\n",
        "    start_y = (28 - new_h) // 2\n",
        "    final_img[start_y:start_y+new_h, start_x:start_x+new_w] = digit_resized\n",
        "\n",
        "    return final_img.astype(np.float32) / 255.0\n",
        "\n",
        "def predict_demo(image_path):\n",
        "    # X·ª≠ l√Ω ·∫£nh\n",
        "    processed_img = preprocess_digit(image_path)\n",
        "    if processed_img is None: return\n",
        "\n",
        "    # D·ª± ƒëo√°n\n",
        "    img_tensor = torch.tensor(processed_img).unsqueeze(0).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        output = cnn_model(img_tensor)\n",
        "        probabilities = torch.nn.functional.softmax(output, dim=1)\n",
        "        prediction = torch.argmax(probabilities, dim=1).item()\n",
        "        confidence = probabilities[0][prediction].item() * 100\n",
        "\n",
        "    # Hi·ªÉn th·ªã k·∫øt qu·∫£ ƒë·∫πp m·∫Øt\n",
        "    plt.figure(figsize=(5, 3))\n",
        "\n",
        "    # ·∫¢nh g·ªëc\n",
        "    original_img = cv2.imread(image_path)\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB))\n",
        "    plt.title(\"·∫¢nh g·ªëc\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    # ·∫¢nh AI nh√¨n th·∫•y\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(processed_img, cmap='gray')\n",
        "    plt.title(f\"AI D·ª± ƒëo√°n: S·ªê {prediction}\\n(ƒê·ªô tin c·∫≠y: {confidence:.1f}%)\", color='blue', fontweight='bold')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# --- PH·∫¶N 5: CH·∫†Y DEMO ---\n",
        "print(\"\\n--- CH∆Ø∆†NG TR√åNH NH·∫¨N DI·ªÜN CH·ªÆ S·ªê VI·∫æT TAY ---\")\n",
        "print(\"M·ªùi th·∫ßy/b·∫°n ch·ªçn ·∫£nh ƒë·ªÉ ki·ªÉm tra:\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "for filename in uploaded.keys():\n",
        "    print(f\"\\nüì∏ ƒêang x·ª≠ l√Ω ·∫£nh: {filename}\")\n",
        "    predict_demo(filename)\n",
        "\n",
        "‚úÖ ƒêang ch·∫°y tr√™n thi·∫øt b·ªã: cpu\n",
        "\n",
        "‚è≥ ƒêang load model...\n",
        "‚úÖ Load model th√†nh c√¥ng! S·∫µn s√†ng demo.\n",
        "\n",
        "--- CH∆Ø∆†NG TR√åNH NH·∫¨N DI·ªÜN CH·ªÆ S·ªê VI·∫æT TAY ---\n",
        "M·ªùi th·∫ßy/b·∫°n ch·ªçn ·∫£nh ƒë·ªÉ ki·ªÉm tra:\n",
        "Upload widget is only available when the cell has been executed in the current browser session. Please rerun this cell to enable.\n",
        "Saving ·∫¢nh ch·ª•p m√†n h√¨nh 2025-11-25 175939.png to ·∫¢nh ch·ª•p m√†n h√¨nh 2025-11-25 175939.png\n",
        "\n",
        "üì∏ ƒêang x·ª≠ l√Ω ·∫£nh: ·∫¢nh ch·ª•p m√†n h√¨nh 2025-11-25 175939.png\n"
      ]
    }
  ]
}